{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала создаём корпус текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Так мы создаём список текстов, которые будут векторизоваться (простите за этот костыльный метод)\n",
    "files = []\n",
    "for i, file in enumerate(os.listdir('C://Users//asus//Desktop//Cybercorpora//Toys')):\n",
    "    jj = os.path.abspath('Desktop\\\\Cybercorpora\\\\Toys\\\\' + file)\n",
    "    dd = re.sub(r'\\\\', '//', jj)\n",
    "    xx = open(jj, 'r', encoding = 'utf-8')\n",
    "    ii = xx.read()\n",
    "    files.append(ii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#токенизируем. Потом можно сделать стоп-лист и вообще почистить тексты, но пока оставим такой игрушечный пример\n",
    "texts = [[word for word in file.lower().split()] for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 13:33:51,755 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-03-20 13:33:51,759 : INFO : built Dictionary(754 unique tokens: ['одной', 'проблемы', 'стал', 'тысяч', 'правовой']...) from 4 documents (total 3318 corpus positions)\n",
      "2018-03-20 13:33:51,761 : INFO : saving Dictionary object under C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.dict, separately None\n",
      "2018-03-20 13:33:51,769 : INFO : saved C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(754 unique tokens: ['одной', 'проблемы', 'стал', 'тысяч', 'правовой']...)\n"
     ]
    }
   ],
   "source": [
    "#векторизуем\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 12:09:47,471 : INFO : storing corpus in Matrix Market format to C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.mm\n",
      "2018-03-20 12:09:47,473 : INFO : saving sparse matrix to C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.mm\n",
      "2018-03-20 12:09:47,474 : INFO : PROGRESS: saving document #0\n",
      "2018-03-20 12:09:47,477 : INFO : saved 4x754 matrix, density=35.312% (1065/3016)\n",
      "2018-03-20 12:09:47,487 : INFO : saving MmCorpus index to C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.mm.index\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.mm', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 12:18:54,266 : INFO : loading Dictionary object from C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.dict\n",
      "2018-03-20 12:18:54,269 : INFO : loaded C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.dict\n",
      "2018-03-20 12:18:54,270 : INFO : loaded corpus index from C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.mm.index\n",
      "2018-03-20 12:18:54,271 : INFO : initializing cython corpus reader from C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.mm\n",
      "2018-03-20 12:18:54,273 : INFO : accepted corpus with 4 documents, 754 features, 1065 non-zero entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(754 unique tokens: ['степени', 'тесно', 'внешней', 'состоит', 'religious']...)\n"
     ]
    }
   ],
   "source": [
    "#Переходим к сходству текстов\n",
    "dictionary = corpora.Dictionary.load('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.dict')\n",
    "corpus = corpora.MmCorpus('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.mm')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 12:09:54,953 : INFO : using serial LSI version on this node\n",
      "2018-03-20 12:09:54,954 : INFO : updating model with new documents\n",
      "2018-03-20 12:09:54,956 : INFO : preparing a new chunk of documents\n",
      "2018-03-20 12:09:54,957 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-03-20 12:09:54,959 : INFO : 1st phase: constructing (754, 102) action matrix\n",
      "2018-03-20 12:09:54,960 : INFO : orthonormalizing (754, 102) action matrix\n",
      "2018-03-20 12:09:54,975 : INFO : 2nd phase: running dense svd on (102, 4) matrix\n",
      "2018-03-20 12:09:54,977 : INFO : computing the final decomposition\n",
      "2018-03-20 12:09:54,978 : INFO : keeping 2 factors (discarding 4.119% of energy spectrum)\n",
      "2018-03-20 12:09:54,980 : INFO : processed documents up to #4\n",
      "2018-03-20 12:09:54,982 : INFO : topic #0(212.270): 0.623*\"в\" + 0.615*\"и\" + 0.193*\"на\" + 0.146*\"с\" + 0.102*\"что\" + 0.096*\"по\" + 0.091*\"как\" + 0.083*\"не\" + 0.076*\"к\" + 0.071*\"-\"\n",
      "2018-03-20 12:09:54,984 : INFO : topic #1(65.727): 0.283*\"в\" + -0.214*\"человека\" + -0.204*\"прав\" + -0.194*\"и\" + 0.175*\"по\" + -0.163*\"права\" + -0.163*\"–\" + 0.159*\"кафедра\" + -0.152*\"во\" + 0.140*\"г.\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.016355223081294334), (1, -0.0509454109782947)]\n"
     ]
    }
   ],
   "source": [
    "#тут я считаю сходство\n",
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Никакого сходства, что разумно - другой язык\n",
    "doc = \"Ich hasse Sprachwissenschaft\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 18.725760398105326), (1, 3.383763575027589)]\n"
     ]
    }
   ],
   "source": [
    "#Попробуем подать политологический текст\n",
    "doc = open('C:/Users/asus/Desktop/Cybercorpora/textstocompare/abhaziya-na-perekrestke-geopoliticheskih-interesov.txt', 'r', encoding = 'utf-8').read()\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 119.34819809284976), (1, -9.592354497226939)]\n"
     ]
    }
   ],
   "source": [
    "#А теперь из педагогики\n",
    "doc = open('C:/Users/asus/Desktop/Cybercorpora/textstocompare/adaptivnost-i-kreativnost-v-stanovlenii-i-razvitii-tvorcheskoy-lichnosti-buduschego-uchitelya-v-sisteme-nepreryvnogo-pedagogicheskogo.txt', 'r', encoding = 'utf-8').read()\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то он считает. Но что? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 147.38810481559895), (1, -44.01744138755173)]\n"
     ]
    }
   ],
   "source": [
    "doc = open('C:/Users/asus/Desktop/Cybercorpora/Toys/1-15-prava-cheloveka-v-traditsionnom-obschestve-vietnama.txt', 'r', encoding = 'utf-8').read()\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Попробуем сравнить два одинаковых текста.\n",
    "files2 = []\n",
    "files2.append(open('C:/Users/asus/Desktop/Cybercorpora/Toys/5-8-determinanty-religioznogo-politicheskogo-ekstremizma.txt', 'r', encoding = 'utf-8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts2 = [[word2 for word2 in file2.lower().split()] for file2 in files2]\n",
    "frequency2 = defaultdict(int)\n",
    "for text2 in texts2:\n",
    "    for token2 in text2:\n",
    "        frequency2[token2] += 1\n",
    "\n",
    "texts2 = [[token2 for token2 in text2 if frequency2[token2] > 1] for text2 in texts2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 13:10:31,413 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-03-20 13:10:31,415 : INFO : built Dictionary(186 unique tokens: ['норм', 'рассматривается', 'religious', 'устойчивый,', 'по']...) from 1 documents (total 662 corpus positions)\n",
      "2018-03-20 13:10:31,416 : INFO : saving Dictionary object under C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.dict, separately None\n",
      "2018-03-20 13:10:31,420 : INFO : saved C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(186 unique tokens: ['норм', 'рассматривается', 'religious', 'устойчивый,', 'по']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary2 = corpora.Dictionary(texts2)\n",
    "dictionary2.save('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.dict')\n",
    "print (dictionary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 13:10:33,394 : INFO : storing corpus in Matrix Market format to C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.mm\n",
      "2018-03-20 13:10:33,395 : INFO : saving sparse matrix to C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.mm\n",
      "2018-03-20 13:10:33,396 : INFO : PROGRESS: saving document #0\n",
      "2018-03-20 13:10:33,398 : INFO : saved 1x186 matrix, density=100.000% (186/186)\n",
      "2018-03-20 13:10:33,401 : INFO : saving MmCorpus index to C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.mm.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 2), (2, 6), (3, 2), (4, 2), (5, 2), (6, 4), (7, 2), (8, 2), (9, 3), (10, 11), (11, 4), (12, 4), (13, 7), (14, 2), (15, 9), (16, 2), (17, 2), (18, 4), (19, 3), (20, 2), (21, 2), (22, 2), (23, 2), (24, 2), (25, 45), (26, 2), (27, 2), (28, 2), (29, 2), (30, 2), (31, 2), (32, 2), (33, 6), (34, 2), (35, 4), (36, 2), (37, 2), (38, 2), (39, 2), (40, 2), (41, 2), (42, 5), (43, 3), (44, 2), (45, 4), (46, 2), (47, 2), (48, 5), (49, 2), (50, 4), (51, 2), (52, 2), (53, 2), (54, 51), (55, 2), (56, 2), (57, 2), (58, 2), (59, 2), (60, 7), (61, 3), (62, 8), (63, 2), (64, 2), (65, 2), (66, 2), (67, 2), (68, 2), (69, 3), (70, 2), (71, 2), (72, 3), (73, 3), (74, 2), (75, 2), (76, 10), (77, 2), (78, 2), (79, 2), (80, 2), (81, 4), (82, 2), (83, 2), (84, 3), (85, 3), (86, 2), (87, 2), (88, 2), (89, 2), (90, 2), (91, 3), (92, 6), (93, 3), (94, 2), (95, 2), (96, 2), (97, 3), (98, 2), (99, 2), (100, 16), (101, 3), (102, 2), (103, 3), (104, 2), (105, 2), (106, 6), (107, 12), (108, 2), (109, 2), (110, 2), (111, 3), (112, 2), (113, 2), (114, 2), (115, 2), (116, 2), (117, 2), (118, 2), (119, 2), (120, 2), (121, 2), (122, 11), (123, 10), (124, 2), (125, 2), (126, 6), (127, 2), (128, 2), (129, 3), (130, 20), (131, 2), (132, 2), (133, 2), (134, 3), (135, 3), (136, 2), (137, 3), (138, 2), (139, 2), (140, 2), (141, 2), (142, 2), (143, 2), (144, 2), (145, 2), (146, 4), (147, 4), (148, 2), (149, 3), (150, 3), (151, 2), (152, 3), (153, 2), (154, 2), (155, 3), (156, 2), (157, 2), (158, 2), (159, 2), (160, 2), (161, 2), (162, 2), (163, 2), (164, 2), (165, 5), (166, 2), (167, 3), (168, 2), (169, 2), (170, 2), (171, 2), (172, 6), (173, 9), (174, 3), (175, 7), (176, 2), (177, 4), (178, 2), (179, 2), (180, 4), (181, 2), (182, 3), (183, 4), (184, 2), (185, 4)]]\n"
     ]
    }
   ],
   "source": [
    "corpus2 = [dictionary2.doc2bow(text2) for text2 in texts2]\n",
    "corpora.MmCorpus.serialize('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.mm', corpus2)\n",
    "print(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 13:10:35,668 : INFO : loading Dictionary object from C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.dict\n",
      "2018-03-20 13:10:35,670 : INFO : loaded C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.dict\n",
      "2018-03-20 13:10:35,671 : INFO : loaded corpus index from C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.mm.index\n",
      "2018-03-20 13:10:35,673 : INFO : initializing cython corpus reader from C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.mm\n",
      "2018-03-20 13:10:35,674 : INFO : accepted corpus with 1 documents, 186 features, 186 non-zero entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(1 documents, 186 features, 186 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "dictionary2 = corpora.Dictionary.load('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.dict')\n",
    "corpus2 = corpora.MmCorpus('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus2.mm')\n",
    "print(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 13:10:37,636 : INFO : using serial LSI version on this node\n",
      "2018-03-20 13:10:37,637 : INFO : updating model with new documents\n",
      "2018-03-20 13:10:37,639 : INFO : preparing a new chunk of documents\n",
      "2018-03-20 13:10:37,640 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-03-20 13:10:37,642 : INFO : 1st phase: constructing (186, 102) action matrix\n",
      "2018-03-20 13:10:37,643 : INFO : orthonormalizing (186, 102) action matrix\n",
      "2018-03-20 13:10:37,650 : INFO : 2nd phase: running dense svd on (102, 1) matrix\n",
      "2018-03-20 13:10:37,651 : INFO : computing the final decomposition\n",
      "2018-03-20 13:10:37,653 : INFO : keeping 1 factors (discarding 0.000% of energy spectrum)\n",
      "2018-03-20 13:10:37,654 : INFO : processed documents up to #1\n",
      "2018-03-20 13:10:37,655 : INFO : topic #0(86.475): 0.590*\"и\" + 0.520*\"в\" + 0.231*\"с\" + 0.185*\"по\" + 0.139*\"политического\" + 0.127*\"of\" + 0.127*\"религиозного\" + 0.116*\"на\" + 0.116*\"религиозный\" + 0.104*\"экстремизм\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus2, id2word=dictionary2, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 86.47543003651363)]\n"
     ]
    }
   ],
   "source": [
    "doc = open('C:/Users/asus/Desktop/Cybercorpora/Toys/5-8-determinanty-religioznogo-politicheskogo-ekstremizma.txt', 'r', encoding = 'utf-8').read()\n",
    "vec_bow = dictionary2.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 73.07277913890472)]\n"
     ]
    }
   ],
   "source": [
    "doc = open('C:/Users/asus/Desktop/Cybercorpora/textstocompare/5-8-determinanty-religioznogo-politicheskogo-ekstremizma.txt', 'r', encoding = 'utf-8').read()\n",
    "vec_bow = dictionary2.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 13:11:24,547 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-03-20 13:11:24,549 : INFO : built Dictionary(231 unique tokens: ['фразеологический', 'процессе', 'вслед', 'человека', 'функционирования']...) from 1 documents (total 886 corpus positions)\n",
      "2018-03-20 13:11:24,550 : INFO : saving Dictionary object under C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.dict, separately None\n",
      "2018-03-20 13:11:24,553 : INFO : saved C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.dict\n",
      "2018-03-20 13:11:24,555 : INFO : storing corpus in Matrix Market format to C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.mm\n",
      "2018-03-20 13:11:24,556 : INFO : saving sparse matrix to C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.mm\n",
      "2018-03-20 13:11:24,557 : INFO : PROGRESS: saving document #0\n",
      "2018-03-20 13:11:24,559 : INFO : saved 1x231 matrix, density=100.000% (231/231)\n",
      "2018-03-20 13:11:24,562 : INFO : saving MmCorpus index to C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.mm.index\n"
     ]
    }
   ],
   "source": [
    "files3 = []\n",
    "files3.append(open('C:/Users/asus/Desktop/Cybercorpora/textstocompare/bazovyye-kontsepty.txt', 'r', encoding = 'cp1251').read())\n",
    "texts3 = [[word3 for word3 in file3.lower().split()] for file3 in files3]\n",
    "frequency3 = defaultdict(int)\n",
    "for text3 in texts3:\n",
    "    for token3 in text3:\n",
    "        frequency3[token3] += 1\n",
    "\n",
    "texts3 = [[token3 for token3 in text3 if frequency3[token3] > 1] for text3 in texts3]\n",
    "dictionary3 = corpora.Dictionary(texts3)\n",
    "dictionary3.save('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.dict')\n",
    "\n",
    "corpus3 = [dictionary3.doc2bow(text3) for text3 in texts3]\n",
    "corpora.MmCorpus.serialize('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.mm', corpus3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 13:11:38,417 : INFO : loading Dictionary object from C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.dict\n",
      "2018-03-20 13:11:38,419 : INFO : loaded C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.dict\n",
      "2018-03-20 13:11:38,420 : INFO : loaded corpus index from C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.mm.index\n",
      "2018-03-20 13:11:38,421 : INFO : initializing cython corpus reader from C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.mm\n",
      "2018-03-20 13:11:38,422 : INFO : accepted corpus with 1 documents, 231 features, 231 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "dictionary3 = corpora.Dictionary.load('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.dict')\n",
    "corpus3 = corpora.MmCorpus('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus3.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-20 13:11:41,084 : INFO : using serial LSI version on this node\n",
      "2018-03-20 13:11:41,085 : INFO : updating model with new documents\n",
      "2018-03-20 13:11:41,087 : INFO : preparing a new chunk of documents\n",
      "2018-03-20 13:11:41,088 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-03-20 13:11:41,089 : INFO : 1st phase: constructing (231, 102) action matrix\n",
      "2018-03-20 13:11:41,090 : INFO : orthonormalizing (231, 102) action matrix\n",
      "2018-03-20 13:11:41,096 : INFO : 2nd phase: running dense svd on (102, 1) matrix\n",
      "2018-03-20 13:11:41,097 : INFO : computing the final decomposition\n",
      "2018-03-20 13:11:41,098 : INFO : keeping 1 factors (discarding 0.000% of energy spectrum)\n",
      "2018-03-20 13:11:41,099 : INFO : processed documents up to #1\n",
      "2018-03-20 13:11:41,101 : INFO : topic #0(121.515): 0.609*\"и\" + 0.593*\"в\" + 0.189*\"с\" + 0.181*\"как\" + 0.115*\"его\" + 0.107*\"или\" + 0.099*\"для\" + 0.099*\"к\" + 0.091*\"-\" + 0.074*\"на\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus3, id2word=dictionary3, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 107.90399111677931)]\n"
     ]
    }
   ],
   "source": [
    "doc = open('C:/Users/asus/Desktop/Cybercorpora/textstocompare/tsennostnaya-kontseptosphera.txt', 'r', encoding = 'cp1251').read()\n",
    "vec_bow = dictionary3.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
