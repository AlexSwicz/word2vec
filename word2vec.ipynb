{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала создаём корпус текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Так мы создаём список текстов, которые будут векторизоваться (простите за этот костыльный метод)\n",
    "files = []\n",
    "for i, file in enumerate(os.listdir('C://Users//asus//Desktop//Cybercorpora//Toys')):\n",
    "    jj = os.path.abspath('Desktop\\\\Cybercorpora\\\\Toys\\\\' + file)\n",
    "    dd = re.sub(r'\\\\', '//', jj)\n",
    "    xx = open(jj, 'r', encoding = 'utf-8')\n",
    "    ii = xx.read()\n",
    "    files.append(ii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#токенизируем. Потом можно сделать стоп-лист и вообще почистить тексты, но пока оставим такой игрушечный пример\n",
    "texts = [[word for word in file.lower().split()] for file in files]\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(754 unique tokens: ['степени', 'тесно', 'внешней', 'состоит', 'religious']...)\n"
     ]
    }
   ],
   "source": [
    "#векторизуем\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.mm', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(4 documents, 754 features, 1065 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "#Переходим к сходству текстов\n",
    "dictionary = corpora.Dictionary.load('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.dict')\n",
    "corpus = corpora.MmCorpus('C:/Users/asus/Desktop/Cybercorpora/Vectors/corpus.mm')\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.016355223081294414), (1, -0.05094541097829459)]\n"
     ]
    }
   ],
   "source": [
    "#тут я считаю сходство\n",
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Никакого сходства, что разумно - другой язык\n",
    "doc = \"Ich hasse Sprachwissenschaft\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 18.725760398105304), (1, 3.3837635750276047)]\n"
     ]
    }
   ],
   "source": [
    "#Попробуем подать политологический текст\n",
    "doc = open('C:/Users/asus/Desktop/Cybercorpora/Toys/textstocompare/abhaziya-na-perekrestke-geopoliticheskih-interesov.txt', 'r', encoding = 'utf-8').read()\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 119.34819809284963), (1, -9.592354497226992)]\n"
     ]
    }
   ],
   "source": [
    "#А теперь из педагогики\n",
    "doc = open('C:/Users/asus/Desktop/Cybercorpora/Toys/textstocompare/adaptivnost-i-kreativnost-v-stanovlenii-i-razvitii-tvorcheskoy-lichnosti-buduschego-uchitelya-v-sisteme-nepreryvnogo-pedagogicheskogo.txt', 'r', encoding = 'utf-8').read()\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то он считает. Но что? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
